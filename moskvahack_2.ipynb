{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7036352,"sourceType":"datasetVersion","datasetId":4048023},{"sourceId":7038682,"sourceType":"datasetVersion","datasetId":4049542}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"nD3EEfKzFftV","outputId":"9417ef1a-daf7-47de-88a7-04664d42a680","execution":{"iopub.status.busy":"2023-11-25T07:18:16.355029Z","iopub.execute_input":"2023-11-25T07:18:16.355370Z","iopub.status.idle":"2023-11-25T07:18:17.361148Z","shell.execute_reply.started":"2023-11-25T07:18:16.355312Z","shell.execute_reply":"2023-11-25T07:18:17.360027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"id":"AO4MWPmnFk7m","outputId":"e542142f-3d09-4c3e-c799-582c337b4889","execution":{"iopub.status.busy":"2023-11-25T07:18:17.363745Z","iopub.execute_input":"2023-11-25T07:18:17.364149Z","iopub.status.idle":"2023-11-25T07:18:17.370359Z","shell.execute_reply.started":"2023-11-25T07:18:17.364110Z","shell.execute_reply":"2023-11-25T07:18:17.369076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download video","metadata":{"id":"hZkBCNk9F6NO"}},{"cell_type":"code","source":"!pip install -q gdown\n%cd {HOME}\n!gdown '1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-'","metadata":{"id":"bkKyyyNxu5EC","outputId":"3a52a801-df82-44e4-ffdf-306e98ca92b5","execution":{"iopub.status.busy":"2023-11-25T07:18:17.371996Z","iopub.execute_input":"2023-11-25T07:18:17.372365Z","iopub.status.idle":"2023-11-25T07:18:33.740468Z","shell.execute_reply.started":"2023-11-25T07:18:17.372314Z","shell.execute_reply":"2023-11-25T07:18:33.739323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SOURCE_VIDEO_PATH = \"/kaggle/input/testmoscow/KRA-2-9-2023-08-22-evening.mp4\"","metadata":{"id":"Y3DjvPRiGIht","execution":{"iopub.status.busy":"2023-11-25T07:18:33.743085Z","iopub.execute_input":"2023-11-25T07:18:33.743415Z","iopub.status.idle":"2023-11-25T07:18:33.748164Z","shell.execute_reply.started":"2023-11-25T07:18:33.743386Z","shell.execute_reply":"2023-11-25T07:18:33.747087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install YOLOv8\n\nIf you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.","metadata":{"id":"C5w5bHwTGUdp"}},{"cell_type":"code","source":"!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()","metadata":{"id":"S2kB2mCmGPmL","outputId":"61af579b-d853-4be7-bfec-556d2c4c60d1","execution":{"iopub.status.busy":"2023-11-25T07:18:33.749420Z","iopub.execute_input":"2023-11-25T07:18:33.749705Z","iopub.status.idle":"2023-11-25T07:18:52.770999Z","shell.execute_reply.started":"2023-11-25T07:18:33.749680Z","shell.execute_reply":"2023-11-25T07:18:52.770038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install Roboflow Supervision","metadata":{"id":"c-Fg7kPTG1xL"}},{"cell_type":"code","source":"!pip install supervision\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport supervision as sv\nprint(\"supervision.__version__:\", sv.__version__)","metadata":{"id":"dbt0QFEn9OFu","outputId":"88a3a60b-ca43-4d3e-99c5-405c170f18f5","execution":{"iopub.status.busy":"2023-11-25T07:18:52.772285Z","iopub.execute_input":"2023-11-25T07:18:52.772720Z","iopub.status.idle":"2023-11-25T07:19:05.123310Z","shell.execute_reply.started":"2023-11-25T07:18:52.772692Z","shell.execute_reply":"2023-11-25T07:19:05.122253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load pre-trained YOLOv8 model","metadata":{"id":"Y99ZDFi4G9zU"}},{"cell_type":"code","source":"MODEL = \"yolov8x.pt\"","metadata":{"id":"uxe67PQVHBCA","execution":{"iopub.status.busy":"2023-11-25T07:19:05.124872Z","iopub.execute_input":"2023-11-25T07:19:05.125242Z","iopub.status.idle":"2023-11-25T07:19:05.130069Z","shell.execute_reply.started":"2023-11-25T07:19:05.125206Z","shell.execute_reply":"2023-11-25T07:19:05.129098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(MODEL)\nmodel.fuse()","metadata":{"id":"9-7SBD_bHDuQ","outputId":"5c7a2988-55b4-4e94-8a40-c38858304418","execution":{"iopub.status.busy":"2023-11-25T07:19:09.957143Z","iopub.execute_input":"2023-11-25T07:19:09.958083Z","iopub.status.idle":"2023-11-25T07:19:12.496074Z","shell.execute_reply.started":"2023-11-25T07:19:09.958042Z","shell.execute_reply":"2023-11-25T07:19:12.495066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict and annotate single frame","metadata":{"id":"COTWRxDhHIz3"}},{"cell_type":"code","source":"# dict maping class_id to class_name\nCLASS_NAMES_DICT = model.model.names\n\n# class_ids of interest - car, bus and truck\nselected_classes = [2, 5, 7]","metadata":{"id":"QEx7Wn7F9Tlc","execution":{"iopub.status.busy":"2023-11-25T07:19:15.655244Z","iopub.execute_input":"2023-11-25T07:19:15.656245Z","iopub.status.idle":"2023-11-25T07:19:15.660723Z","shell.execute_reply.started":"2023-11-25T07:19:15.656205Z","shell.execute_reply":"2023-11-25T07:19:15.659653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import supervision as sv\nimport numpy as np","metadata":{"id":"noOycxILHjYI","execution":{"iopub.status.busy":"2023-11-25T07:19:17.408956Z","iopub.execute_input":"2023-11-25T07:19:17.409351Z","iopub.status.idle":"2023-11-25T07:19:17.413559Z","shell.execute_reply.started":"2023-11-25T07:19:17.409293Z","shell.execute_reply":"2023-11-25T07:19:17.412597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create frame generator\ngenerator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n# create instance of BoxAnnotator\nbox_annotator = sv.BoxAnnotator(thickness=2, text_thickness=1, text_scale=0.5)\n# acquire first video frame\niterator = iter(generator)\nframe = next(iterator)\n# model prediction on single frame and conversion to supervision Detections\nresults = model(frame, verbose=False)[0]\n\n# convert to Detections\ndetections = sv.Detections.from_ultralytics(results)\n# only consider class id from selected_classes define above\ndetections = detections[np.isin(detections.class_id, selected_classes)]\n\n# format custom labels\nlabels = [\n    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n    for _, _, confidence, class_id, _ in detections\n]\n\n# annotate and display frame\nanotated_frame=box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n\n%matplotlib inline\nsv.plot_image(anotated_frame, (16,16))","metadata":{"id":"ZuNPZ2hvHeZV","outputId":"189ab369-84be-4ce0-c4fe-877bcb6064be","execution":{"iopub.status.busy":"2023-11-25T07:19:20.726437Z","iopub.execute_input":"2023-11-25T07:19:20.726819Z","iopub.status.idle":"2023-11-25T07:19:29.473450Z","shell.execute_reply.started":"2023-11-25T07:19:20.726787Z","shell.execute_reply":"2023-11-25T07:19:29.472409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport numpy as np\n\ndef convert_coordinates_to_pixels(areas, zones, frame_resolution):\n    pixel_coordinates = []\n\n    for area in areas:\n        polygon = np.array(area)\n        polygon[:, 0] *= frame_resolution[0]\n        polygon[:, 1] *= frame_resolution[1]\n        pixel_coordinates.append(polygon)\n\n    pixel_zone_coordinates = []\n\n    for zone in zones:\n        polygon = np.array(zone)\n        polygon[:, 0] *= frame_resolution[0]\n        polygon[:, 1] *= frame_resolution[1]\n        pixel_zone_coordinates.append(polygon)\n\n    return pixel_coordinates, pixel_zone_coordinates\n\n# Загрузка данных из JSON-файла\njson_file_path = \"/kaggle/input/testmoscow/markup/jsons/KRA-2-9-2023-08-22-evening.json\"  # Замените на путь к вашему JSON-файлу\nwith open(json_file_path, \"r\") as json_file:\n    data = json.load(json_file)\n\n# Разрешение кадра\nframe_resolution = (1920, 1080)  # Замените на разрешение вашего видео\n\n# Преобразование координат в пиксели\npixel_areas, pixel_zones = convert_coordinates_to_pixels(data[\"areas\"], data[\"zones\"], frame_resolution)\n\n# Вывод координат в пикселях\nprint(\"Pixel Coordinates:\")\nfor i, polygon in enumerate(pixel_areas):\n    print(f\"Area {i + 1} coordinates:\\n{polygon}\")\n\nprint(\"\\nPixel Zone Coordinates:\")\nfor i, polygon in enumerate(pixel_zones):\n    print(f\"Zone {i + 1} coordinates:\\n{polygon}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-25T07:19:47.532617Z","iopub.execute_input":"2023-11-25T07:19:47.533536Z","iopub.status.idle":"2023-11-25T07:19:47.563846Z","shell.execute_reply.started":"2023-11-25T07:19:47.533499Z","shell.execute_reply":"2023-11-25T07:19:47.562892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict and annotate whole video","metadata":{"id":"Kc0NETYnJWex"}},{"cell_type":"code","source":"# settings\nLINE_START = sv.Point(632, 467)\nLINE_END = sv.Point(646,510)\n\nTARGET_VIDEO_PATH = f\"{HOME}/vehicle-counting-result-with-counter.mp4\"","metadata":{"id":"7Qwykp5K9VdK","execution":{"iopub.status.busy":"2023-11-25T07:26:28.385125Z","iopub.execute_input":"2023-11-25T07:26:28.385566Z","iopub.status.idle":"2023-11-25T07:26:28.390233Z","shell.execute_reply.started":"2023-11-25T07:26:28.385532Z","shell.execute_reply":"2023-11-25T07:26:28.389364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)","metadata":{"id":"kTBvc5FDJcyw","outputId":"0d902b43-24f0-4b17-fe4d-80cca908fc5e","execution":{"iopub.status.busy":"2023-11-25T07:26:29.767340Z","iopub.execute_input":"2023-11-25T07:26:29.767707Z","iopub.status.idle":"2023-11-25T07:26:29.804977Z","shell.execute_reply.started":"2023-11-25T07:26:29.767679Z","shell.execute_reply":"2023-11-25T07:26:29.804065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create BYTETracker instance\nbyte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=15)\n\n# create VideoInfo instance\nvideo_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n\n# create frame generator\ngenerator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n\n# create LineZone instance, it is previously called LineCounter class\nline_zone = sv.LineZone(start=LINE_START, end=LINE_END)\n\n# create instance of BoxAnnotator\nbox_annotator = sv.BoxAnnotator(thickness=2, text_thickness=1, text_scale=0.5)\n\n# create instance of TraceAnnotator\ntrace_annotator = sv.TraceAnnotator(thickness=1, trace_length=10)\n\n# create LineZoneAnnotator instance, it is previously called LineCounterAnnotator class\nline_zone_annotator = sv.LineZoneAnnotator(thickness=1, text_thickness=1, text_scale=0.5)\n","metadata":{"id":"UdnkBZVn9Xyb","execution":{"iopub.status.busy":"2023-11-25T07:26:34.329763Z","iopub.execute_input":"2023-11-25T07:26:34.330562Z","iopub.status.idle":"2023-11-25T07:26:34.357326Z","shell.execute_reply.started":"2023-11-25T07:26:34.330527Z","shell.execute_reply":"2023-11-25T07:26:34.356570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define call back function to be used in video processing\ndef callback(frame: np.ndarray, index:int) -> np.ndarray:\n    # model prediction on single frame and conversion to supervision Detections\n    results = model(frame, verbose=False)[0]\n    detections = sv.Detections.from_ultralytics(results)\n    # only consider class id from selected_classes define above\n    detections = detections[np.isin(detections.class_id, selected_classes)]\n    # tracking detections\n    detections = byte_tracker.update_with_detections(detections)\n    labels = [\n    f\"#{tracker_id} {model.model.names[class_id]} {detection.confidence:0.2f}\" +\n    (f\" @ ({int(x)}, {int(y)}) pixels\" if len(detection) == 6 else \"\")\n    for x, y, _, class_id, tracker_id, detection in detections\n]\n    annotated_frame = trace_annotator.annotate(\n        scene=frame.copy(),\n        detections=detections\n    )\n    annotated_frame=box_annotator.annotate(\n        scene=annotated_frame,\n        detections=detections,\n        labels=labels)\n\n    # update line counter\n    line_zone.trigger(detections)\n    # return frame with box and line annotated result\n    return  line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n\n# process the whole video\nsv.process_video(\n    source_path = SOURCE_VIDEO_PATH,\n    target_path = TARGET_VIDEO_PATH,\n    callback=callback\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T07:37:02.673611Z","iopub.execute_input":"2023-11-25T07:37:02.673984Z","iopub.status.idle":"2023-11-25T07:37:02.924931Z","shell.execute_reply.started":"2023-11-25T07:37:02.673956Z","shell.execute_reply":"2023-11-25T07:37:02.923509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# define call back function to be used in video processing\ndef callback(frame: np.ndarray, index:int) -> np.ndarray:\n    # model prediction on single frame and conversion to supervision Detections\n    results = model(frame, verbose=False)[0]\n    detections = sv.Detections.from_ultralytics(results)\n    # only consider class id from selected_classes define above\n    detections = detections[np.isin(detections.class_id, selected_classes)]\n    # tracking detections\n    detections = byte_tracker.update_with_detections(detections)\n    labels = [\n        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n        for _, _, confidence, class_id, tracker_id\n        in detections\n    ]\n    annotated_frame = trace_annotator.annotate(\n        scene=frame.copy(),\n        detections=detections\n    )\n    annotated_frame=box_annotator.annotate(\n        scene=annotated_frame,\n        detections=detections,\n        labels=labels)\n\n    # update line counter\n    line_zone.trigger(detections)\n    # return frame with box and line annotated result\n    return  line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n\n# process the whole video\nsv.process_video(\n    source_path = SOURCE_VIDEO_PATH,\n    target_path = TARGET_VIDEO_PATH,\n    callback=callback\n)","metadata":{},"execution_count":null,"outputs":[]}]}